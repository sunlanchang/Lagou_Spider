{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LagouCrawl(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.url = \"https://www.lagou.com/jobs/positionAjax.json\"\n",
    "        # 请求头\n",
    "        self.headers = {\n",
    "            \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.79 Safari/537.36\",\n",
    "            \"Referer\": \"https://www.lagou.com/jobs/list_python\",\n",
    "            \"Cookie\": \"_ga=GA1.2.2032920817.1520234065; _gid=GA1.2.2007661123.1520234065; user_trace_token=20180305151430-d90e083a-2044-11e8-9cf0-525400f775ce; LGUID=20180305151430-d90e0bf2-2044-11e8-9cf0-525400f775ce; showExpriedIndex=1; showExpriedCompanyHome=1; showExpriedMyPublish=1; hasDeliver=0; index_location_city=%E5%8C%97%E4%BA%AC; JSESSIONID=ABAAABAACBHABBIECE1AB2B1B3ED00095A40CC2532D48F6; hideSliderBanner20180305WithTopBannerC=1; Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1520234067,1520237823,1520298106; LGSID=20180306090145-f0f266a0-20d9-11e8-b126-5254005c3644; _putrc=6F0BC7CDE26E29D5; login=true; unick=%E5%AD%99%E5%85%B0%E6%98%8C; gate_login_token=d3d779887321e8280503a885cdda9b6badc9944fb3549bb7; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1520299986; _gat=1; LGRID=20180306093308-530763f4-20de-11e8-9d87-525400f775ce; TG-TRACK-CODE=index_search; SEARCH_ID=f130bb4a5c0140d7928602bd7d6d5054\"\n",
    "        }\n",
    "        # 查询字符串\n",
    "        self.params = {\n",
    "            \"city\": \"北京\",\n",
    "            \"needAddtionalResult\": False,\n",
    "            \"isSchoolJob\": 0\n",
    "        }\n",
    "        # 表单数据\n",
    "        self.data = {\n",
    "            \"first\": True,\n",
    "            \"pn\": '1',\n",
    "            \"kd\": '技术总监'\n",
    "        }\n",
    "\n",
    "    def start_crawl(self, page=1):\n",
    "        self.data['pn'] = str(page)\n",
    "        response = requests.post(\n",
    "            self.url, params=self.params, data=self.data, headers=self.headers)\n",
    "        data = response.content.decode('utf-8')\n",
    "        dict_data = json.loads(data)\n",
    "        return dict_data\n",
    "\n",
    "    def get_page_num(self):\n",
    "        data = self.start_crawl()\n",
    "        items = data['content']['positionResult']['totalCount']\n",
    "        import math\n",
    "        page = math.ceil(items/15)\n",
    "        print(page)\n",
    "        if page > 30:\n",
    "            return 30\n",
    "        else:\n",
    "            return page\n",
    "\n",
    "    def save(self, data, filename):\n",
    "        position_list = data[\"content\"][\"positionResult\"][\"result\"]\n",
    "\n",
    "        col = ['positionId', 'positionLables', 'positionName', 'positionAdvantage',\n",
    "               'firstType', 'secondType', 'workYear', 'education', 'salary', 'isSchoolJob', 'companyId', 'companyShortName',\n",
    "               'companyFullName', 'companySize', 'financeStage', 'industryField', 'industryLables', 'createTime',\n",
    "               'formatCreateTime', 'city', 'district', 'businessZones', 'linestaion', 'stationname']\n",
    "\n",
    "        f = open('data/'+filename, 'a', encoding='utf-8')\n",
    "        for position in position_list:\n",
    "            line = \"\"\n",
    "            flag = False\n",
    "            for e in col:\n",
    "                if flag:\n",
    "                    line += ',' + \"\\\"\"+str(position[e]) + \"\\\"\"\n",
    "                else:\n",
    "                    line += \"\\\"\"+str(position[e]) + \"\\\"\"\n",
    "                flag = True\n",
    "            line += '\\n'\n",
    "            f.write(line)\n",
    "\n",
    "    def get_position_detail(self, data):\n",
    "        position_id_list = []\n",
    "        position_list = data['content']['positionResult']['result']\n",
    "        for position in position_list:\n",
    "            position_id_list.append(position['positionId'])\n",
    "        print('po id',position_id_list)\n",
    "        for id in position_id_list:\n",
    "            try:\n",
    "                url = 'https://www.lagou.com/jobs/'\n",
    "                url += str(id)+'.html'\n",
    "                print(url)\n",
    "                html_doc = requests.get(url, headers=self.headers).text\n",
    "                soup = BeautifulSoup(html_doc, 'lxml')\n",
    "                bonus = soup.select('.job-advantage p')\n",
    "                for bo in bonus:\n",
    "                    print('benifit:',bo.text.strip())\n",
    "                desc = soup.select('.job_bt p')\n",
    "                for de in desc:\n",
    "                    print('description:',de.text.strip())\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "positionName_list = []\n",
    "with open('position_name_tmp.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        positionName_list += line.strip().split(',')\n",
    "\n",
    "city_list = ['', '北京', '上海', '杭州',\n",
    "             '广州', '深圳', '成都']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city:  position_name: Java\n",
      "city:  position_name: C++\n",
      "city: 北京 position_name: Java\n",
      "city: 北京 position_name: C++\n",
      "city: 上海 position_name: Java\n",
      "city: 上海 position_name: C++\n",
      "city: 杭州 position_name: Java\n",
      "city: 杭州 position_name: C++\n",
      "city: 广州 position_name: Java\n",
      "city: 广州 position_name: C++\n",
      "city: 深圳 position_name: Java\n",
      "city: 深圳 position_name: C++\n",
      "city: 成都 position_name: Java\n",
      "city: 成都 position_name: C++\n"
     ]
    }
   ],
   "source": [
    "for city in city_list:\n",
    "    try:\n",
    "        for name in positionName_list:\n",
    "            try:\n",
    "                print('city: {} position_name: {}'.format(city, name))\n",
    "                spider = LagouCrawl()\n",
    "                spider.params['city'] = city\n",
    "                spider.data['kd'] = name\n",
    "                page_num = spider.get_page_num()\n",
    "                for page in range(1, page_num+1):\n",
    "                    data = spider.start_crawl(page)\n",
    "                    spider.get_position_detail(data)\n",
    "            except:\n",
    "                pass\n",
    "    except:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
